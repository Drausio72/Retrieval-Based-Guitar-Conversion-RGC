{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Drausio72/Retrieval-Based-Guitar-Conversion-RGC/blob/main/RGC_Incrememental.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGhmauqOqgj1",
        "outputId": "35079e84-902a-422a-f0c2-7fab02644759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.11.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.36.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.62.2)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.4.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "#@title **1. Mount Drive and Install Libraries**\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "!pip install librosa tensorflow\n",
        "\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.metrics import mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **2. Define Data Paths and Model Name**\n",
        "base_path = \"/content/drive/MyDrive/AudioData\"\n",
        "clean_path = os.path.join(base_path, \"Clean_Files\")\n",
        "distorted_path = os.path.join(base_path, \"Distorted_Files\")\n",
        "model_name = \"DI_Model\"\n",
        "\n",
        "# Validation paths\n",
        "validation_clean_path = os.path.join(base_path, \"Validation_Clean_Files\")\n",
        "validation_distorted_path = os.path.join(base_path, \"Validation_Distorted_Files\")"
      ],
      "metadata": {
        "id": "KO9KNwnuqq_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **3. Define Utility Functions for Data Preparation and Loading**\n",
        "def load_audio_files(path, sr=44100, duration=5, pad=True):\n",
        "    \"\"\"Load and pad/trim an audio file to the same length.\"\"\"\n",
        "    audio, _ = librosa.load(path, sr=sr, mono=True, duration=duration)\n",
        "    if pad:\n",
        "        # Pad or trim to fixed length\n",
        "        audio = librosa.util.fix_length(audio, size=sr*duration)\n",
        "    return audio\n",
        "\n",
        "def audio_to_spectrogram(signal, n_fft=2048, hop_length=512):\n",
        "    \"\"\"Convert an audio waveform to a normalized spectrogram.\"\"\"\n",
        "    S = librosa.stft(signal, n_fft=n_fft, hop_length=hop_length)\n",
        "    S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)\n",
        "    # Normalize spectrogram to be in range [0, 1]\n",
        "    S_db -= S_db.min()\n",
        "    S_db /= S_db.max()\n",
        "    return S_db\n",
        "\n",
        "def get_files_from_directory(directory):\n",
        "    \"\"\" List all .wav files in the specified directory \"\"\"\n",
        "    return [os.path.join(directory, f) for f in os.listdir(directory) if f.endswith('.wav')]\n"
      ],
      "metadata": {
        "id": "O-t2jfyirT7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **4. Prepare Data for Training**\n",
        "def prepare_data(clean_dir, distorted_dir):\n",
        "    clean_files = get_files_from_directory(clean_dir)\n",
        "    distorted_files = get_files_from_directory(distorted_dir)\n",
        "    assert len(clean_files) == len(distorted_files), \"Mismatch in file counts between clean and distorted data.\"\n",
        "\n",
        "    clean_signals = [load_audio_files(f) for f in clean_files]\n",
        "    distorted_signals = [load_audio_files(f) for f in distorted_files]\n",
        "\n",
        "    X_train = np.array([audio_to_spectrogram(signal) for signal in distorted_signals])\n",
        "    y_train = np.array([audio_to_spectrogram(signal) for signal in clean_signals])\n",
        "\n",
        "    return X_train, y_train\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQI-fSFMrZar",
        "outputId": "b281542a-6ced-4b10-f6d1-e6044628c90f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (1, 1025, 431, 1)\n",
            "y_train shape: (1, 1025, 431, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **5. Define Model Architecture**\n",
        "def build_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    outputs = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "# Prepare initial training data\n",
        "X_train, y_train = prepare_data(clean_path, distorted_path)\n",
        "\n",
        "# Build and Compile Model**\n",
        "input_shape = X_train.shape[1:]\n",
        "model = build_model(input_shape)\n",
        "model.compile(optimizer='adam', loss='mse')"
      ],
      "metadata": {
        "id": "ooYCs9xmSVxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d7kUcVvArjwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **6. Set up Checkpoints and Resume Training**\n",
        "checkpoint_dir = f'/content/drive/MyDrive/Training/{model_name}/'\n",
        "checkpoint_path = os.path.join(checkpoint_dir, \"cp-{epoch:04d}.ckpt\")\n",
        "if not os.path.exists(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)\n",
        "\n",
        "latest_checkpoint = tf.train.latest_checkpoint(checkpoint_dir)\n",
        "if (latest_checkpoint):\n",
        "    model.load_weights(latest_checkpoint)\n",
        "    print(f\"Resuming training from checkpoint: {latest_checkpoint}\")\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1)\n"
      ],
      "metadata": {
        "id": "SchRyJTermZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44183272-d7bd-4680-abb1-2de67282bd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resuming training from checkpoint: /content/drive/MyDrive/Training/DI_Model/cp-1490.ckpt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **7. Train and Save Model**\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
        "batch_size = 32  # Start with 32, consider doubling to see effects\n",
        "epochs = 100  # Start with 100, use early stopping to halt if necessary\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "model.fit(X_train, y_train,\n",
        "          #validation_data=(X_val, y_val),\n",
        "          epochs=epochs,\n",
        "          batch_size=batch_size,\n",
        "          callbacks=[early_stopping, tensorboard_callback])\n",
        "final_model_path = f'/content/drive/MyDrive/Models/{model_name}.h5'\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)  # Adjust learning rate as needed\n",
        "model.compile(optimizer=optimizer, loss='mse')\n",
        "model.save(final_model_path)\n",
        "\n",
        "print(f\"Model saved to {final_model_path}\")\n"
      ],
      "metadata": {
        "id": "p8Ot6UQKrvBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **8. Calculate Error Before Incremental Training**\n",
        "def calculate_error(model, clean_dir, distorted_dir):\n",
        "    clean_files = get_files_from_directory(clean_dir)\n",
        "    distorted_files = get_files_from_directory(distorted_dir)\n",
        "\n",
        "    clean_signals = [load_audio_files(f) for f in clean_files]\n",
        "    distorted_signals = [load_audio_files(f) for f in distorted_files]\n",
        "\n",
        "    X_val = np.array([audio_to_spectrogram(signal) for signal in distorted_signals])\n",
        "    y_val = np.array([audio_to_spectrogram(signal) for signal in clean_signals])\n",
        "\n",
        "    predictions = model.predict(X_val)\n",
        "    mse = mean_squared_error(y_val.flatten(), predictions.flatten())\n",
        "\n",
        "    return mse\n",
        "\n",
        "# Calculate and print error before incremental training\n",
        "error_before = calculate_error(model, validation_clean_path, validation_distorted_path)\n",
        "print(f\"Error before incremental training: {error_before}\")"
      ],
      "metadata": {
        "id": "4EmPQnnwS_T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title **9. Incremental Training**\n",
        "# Example for handling new data periodically\n",
        "# This is a placeholder; in practice, schedule this as needed\n",
        "new_clean_path = os.path.join(base_path, \"New_Clean_Files\")\n",
        "new_distorted_path = os.path.join(base_path, \"New_Distorted_Files\")\n",
        "\n",
        "new_X_train, new_y_train = prepare_data(new_clean_path, new_distorted_path)\n",
        "model.fit(new_X_train, new_y_train, epochs=5, batch_size=10, callbacks=[cp_callback])\n",
        "\n",
        "# Save the updated model\n",
        "model.save(final_model_path)\n",
        "print(\"Model updated with new data and saved again.\")\n",
        "\n",
        "#@title **10. Calculate Error After Incremental Training**\n",
        "# Calculate and print error after incremental training\n",
        "error_after = calculate_error(model, validation_clean_path, validation_distorted_path)\n",
        "print(f\"Error after incremental training: {error_after}\")\n",
        "\n",
        "# Calculate percentage improvement\n",
        "error_improvement = ((error_before - error_after) / error_before) * 100\n",
        "print(f\"Error percentage improvement: {error_improvement:.2f}%\")"
      ],
      "metadata": {
        "id": "diXDdGSFryQV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}